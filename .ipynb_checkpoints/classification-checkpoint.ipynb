{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Make', 'Model', 'Year', 'Engine HP', 'Engine Cylinders', 'Transmission Type', 'Vehicle Style', 'highway MPG', 'city mpg', 'MSRP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64640e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d33cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ee29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'msrp' : 'price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a245b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023a9ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transmission_type'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "numerical_columns = ['year', 'engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg']\n",
    "\n",
    "correlation_matrix = df[numerical_columns].corr()\n",
    "\n",
    "# Finding the features with the largest correlation\n",
    "highest_corr = correlation_matrix.abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "top_corr_features = highest_corr[highest_corr.index.get_level_values(0) != highest_corr.index.get_level_values(1)].index[:2]\n",
    "\n",
    "# Print the correlation matrix and the two features with the biggest correlation\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "print(\"\\nTwo features with the highest correlation:\")\n",
    "print(top_corr_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdeeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Making price binary\n",
    "df['above_average'] = (df['price'] > df['price'].mean()).astype(int)\n",
    "\n",
    "# Splitting the data into train/val/test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # 20% of the original data for validation\n",
    "\n",
    "# Removing the target variable from the datasets\n",
    "X_train = train_data.drop('above_average', axis=1)\n",
    "X_val = val_data.drop('above_average', axis=1)\n",
    "\n",
    "# Selecting categorical features\n",
    "categorical_features = ['make', 'model', 'transmission_type', 'vehicle_style']\n",
    "\n",
    "# Encoding categorical features\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_encoded = dv.fit_transform(X_train[categorical_features].to_dict(orient='records'))\n",
    "\n",
    "# Calculating mutual information scores\n",
    "mi_scores = []\n",
    "for feature in categorical_features:\n",
    "    mi_score = mutual_info_score(X_train_encoded[:, dv.feature_names_.index(f'{feature}={value}')], train_data['above_average'])\n",
    "    mi_scores.append((feature, round(mi_score, 2)))\n",
    "\n",
    "# Printing the mutual information scores\n",
    "print(\"Mutual Information Scores:\")\n",
    "for feature, score in mi_scores:\n",
    "    print(f\"{feature}: {score}\")\n",
    "\n",
    "# Finding the variable with the lowest mutual information score\n",
    "lowest_mi_variable = min(mi_scores, key=lambda x: x[1])[0]\n",
    "print(\"\\nVariable with the lowest mutual information score:\", lowest_mi_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73956cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate the target variable 'above_average' and features\n",
    "X_train = train_data.drop(['price', 'above_average'], axis=1)\n",
    "y_train = train_data['above_average']\n",
    "X_val = val_data.drop(['price', 'above_average'], axis=1)\n",
    "y_val = val_data['above_average']\n",
    "\n",
    "# Define categorical features for one-hot encoding\n",
    "categorical_features = ['make', 'model', 'transmission_type', 'vehicle_style']\n",
    "\n",
    "# Create a preprocessor to handle one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline with logistic regression model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model on the training dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation dataset\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation dataset\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy on the validation dataset:\", round(accuracy_val, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "# Separate the target variable 'above_average' and features\n",
    "X_train = train_data.drop(['price', 'above_average'], axis=1)\n",
    "y_train = train_data['above_average']\n",
    "X_val = val_data.drop(['price', 'above_average'], axis=1)\n",
    "y_val = val_data['above_average']\n",
    "\n",
    "# Define categorical features for one-hot encoding\n",
    "categorical_features = ['make', 'model', 'transmission_type', 'vehicle_style']\n",
    "\n",
    "# Create a preprocessor to handle one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline with logistic regression model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model on the training dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy on the validation dataset (original accuracy)\n",
    "accuracy_original = accuracy_score(y_val, model.predict(X_val))\n",
    "\n",
    "# Calculate the difference for each feature\n",
    "feature_differences = {}\n",
    "for feature in X_train.columns:\n",
    "    # Clone the original model\n",
    "    model_clone = clone(model)\n",
    "    \n",
    "    # Exclude the current feature\n",
    "    X_train_excluded = X_train.drop(feature, axis=1)\n",
    "    X_val_excluded = X_val.drop(feature, axis=1)\n",
    "    \n",
    "    # Fit the model without the current feature\n",
    "    model_clone.fit(X_train_excluded, y_train)\n",
    "    \n",
    "    # Calculate accuracy without the current feature\n",
    "    accuracy_excluded = accuracy_score(y_val, model_clone.predict(X_val_excluded))\n",
    "    \n",
    "    # Calculate the difference\n",
    "    difference = accuracy_original - accuracy_excluded\n",
    "    \n",
    "    # Store the difference for the current feature\n",
    "    feature_differences[feature] = difference\n",
    "\n",
    "# Find the feature with the smallest difference\n",
    "smallest_difference_feature = min(feature_differences, key=feature_differences.get)\n",
    "\n",
    "# Print the differences for each feature\n",
    "print(\"Differences for each feature:\")\n",
    "for feature, difference in feature_differences.items():\n",
    "    print(f\"{feature}: {round(difference, 2)}\")\n",
    "\n",
    "print(\"\\nFeature with the smallest difference:\", smallest_difference_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate the target variable 'above_average' and features\n",
    "X_train = train_data.drop(['price', 'above_average'], axis=1)\n",
    "y_train = train_data['price']\n",
    "X_val = val_data.drop(['price', 'above_average'], axis=1)\n",
    "y_val = val_data['price']\n",
    "\n",
    "# Apply logarithmic transformation to the target variable 'price'\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "\n",
    "# Define alpha values to try\n",
    "alphas = [0, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Create a pipeline with Ridge regression model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', Ridge(solver='sag', random_state=42))\n",
    "])\n",
    "\n",
    "# Dictionary to store RMSE scores for each alpha\n",
    "rmse_scores = {}\n",
    "\n",
    "# Fit the model for each alpha and calculate RMSE on the validation set\n",
    "for alpha in alphas:\n",
    "    pipeline.set_params(regressor__alpha=alpha)\n",
    "    pipeline.fit(X_train, y_train_log)\n",
    "    y_val_log_pred = pipeline.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_log, y_val_log_pred))\n",
    "    rmse_scores[alpha] = rmse\n",
    "\n",
    "# Find the alpha with the best RMSE\n",
    "best_alpha = min(rmse_scores, key=rmse_scores.get)\n",
    "\n",
    "# Print the RMSE scores and the best alpha\n",
    "print(\"RMSE scores for each alpha:\")\n",
    "for alpha, rmse in rmse_scores.items():\n",
    "    print(f\"Alpha {alpha}: {round(rmse, 3)}\")\n",
    "\n",
    "print(\"\\nBest alpha:\", best_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c2bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
